{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pandas.core.common import flatten\n",
    "import copy\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import wandb\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def prepare(batch_size=64):\\n    transform = transforms.Compose([\\n    transforms.Resize((256,256)), \\n    transforms.ToTensor(),\\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\\n    ])\\n    classes = (\\'Amphibia\\', \\'Animalia\\', \\'Arachnida\\', \\'Aves\\', \\'Fungi\\', \\'Insecta\\', \\'Mammalia\\', \\'Mollusca\\', \\'Plantae\\', \\'Reptilia\\')\\n    train_data_path = \\'/home/bincy/A2/CS-6910-A2/inaturalist_12K/train\\'\\n    test_data_path = \\'/home/bincy/A2/CS-6910-A2/inaturalist_12K/val\\'\\n\\n    # Create datasets from the directories\\n    train_data_path = \\'/home/bincy/A2/CS-6910-A2/inaturalist_12K/train\\'\\n    test_data_path = \\'/home/bincy/A2/CS-6910-A2/inaturalist_12K/val\\'\\n\\n    # Create datasets from the directories\\n    train_dataset = datasets.ImageFolder(train_data_path, transform=transform)\\n    test_dataset = datasets.ImageFolder(test_data_path, transform=transform)\\n    class_labels = np.array(train_dataset.targets)\\n\\n    validation_size = 0.2\\n\\n    stratified_splitter = StratifiedShuffleSplit(n_splits=1, test_size=validation_size, random_state=42)\\n\\n\\n    train_indices, validation_indices = next(stratified_splitter.split(train_dataset, class_labels))\\n\\n    # Create a balanced validation subset\\n    validation_targets = class_labels[validation_indices]\\n    unique_classes, class_counts = np.unique(validation_targets, return_counts=True)\\n    min_class_count = min(class_counts)\\n\\n    balanced_validation_indices = []\\n    for cls in unique_classes:\\n        cls_indices = validation_indices[validation_targets == cls]\\n        balanced_validation_indices.extend(np.random.choice(cls_indices, min_class_count, replace=False))\\n\\n    # Create subsets using the indices\\n    train_subset = torch.utils.data.Subset(train_dataset, train_indices)\\n    validation_subset = torch.utils.data.Subset(train_dataset, balanced_validation_indices)\\n    print(type(train_subset),type(validation_subset))\\n    #validation split ensuring equal represntation of classes\\n\\n    class_labels = np.array(train_dataset.targets)\\n\\n    validation_size = 0.2\\n\\n    stratified_splitter = StratifiedShuffleSplit(n_splits=1, test_size=validation_size, random_state=42)\\n\\n\\n    train_indices, validation_indices = next(stratified_splitter.split(train_dataset, class_labels))\\n\\n    # Create a balanced validation subset\\n    validation_targets = class_labels[validation_indices]\\n    unique_classes, class_counts = np.unique(validation_targets, return_counts=True)\\n    min_class_count = min(class_counts)\\n\\n    balanced_validation_indices = []\\n    for cls in unique_classes:\\n        cls_indices = validation_indices[validation_targets == cls]\\n        balanced_validation_indices.extend(np.random.choice(cls_indices, min_class_count, replace=False))\\n\\n    # Create subsets using the indices\\n    train_subset = torch.utils.data.Subset(train_dataset, train_indices)\\n    validation_subset = torch.utils.data.Subset(train_dataset, balanced_validation_indices)\\n    print(type(train_subset),type(validation_subset))\\n\\n# Now train_subset and validation_subset contain data with balanced class representation\\n  \\n    trainloader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)\\n    validationloader = torch.utils.data.DataLoader(validation_subset, batch_size=batch_size, shuffle=True)\\n    testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\\n    print(type(trainloader))\\n    # Check images\\n    dataiter = iter(trainloader)\\n    images, labels = next(dataiter)\\n\\n    print(\"the images batch\",images.shape)\\n\\n    print(\"a single item\",images[3].shape)\\n    print(\"label of item\",labels[3].item())\\n    #visualising\\n    img = images[3]\\n    print(type(img))\\n    npimg = img.numpy()\\n    print(npimg.shape)\\n    npimg = np.transpose(npimg, (1, 2, 0))\\n    print(npimg.shape)\\n    plt.figure(figsize = (4,4))\\n    plt.imshow(npimg)\\n    plt.title(classes[labels[3]])\\n    plt.show()\\n    imshow(torchvision.utils.make_grid(images))\\n    print(\\' \\'.join(classes[labels[j]] for j in range(batch_size)))\\n\\n    return trainloader,validationloader,testloader\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def prepare(batch_size=64):\n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize((256,256)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "    classes = ('Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia')\n",
    "    train_data_path = '/home/bincy/A2/CS-6910-A2/inaturalist_12K/train'\n",
    "    test_data_path = '/home/bincy/A2/CS-6910-A2/inaturalist_12K/val'\n",
    "\n",
    "    # Create datasets from the directories\n",
    "    train_data_path = '/home/bincy/A2/CS-6910-A2/inaturalist_12K/train'\n",
    "    test_data_path = '/home/bincy/A2/CS-6910-A2/inaturalist_12K/val'\n",
    "\n",
    "    # Create datasets from the directories\n",
    "    train_dataset = datasets.ImageFolder(train_data_path, transform=transform)\n",
    "    test_dataset = datasets.ImageFolder(test_data_path, transform=transform)\n",
    "    class_labels = np.array(train_dataset.targets)\n",
    "\n",
    "    validation_size = 0.2\n",
    "\n",
    "    stratified_splitter = StratifiedShuffleSplit(n_splits=1, test_size=validation_size, random_state=42)\n",
    "\n",
    "\n",
    "    train_indices, validation_indices = next(stratified_splitter.split(train_dataset, class_labels))\n",
    "\n",
    "    # Create a balanced validation subset\n",
    "    validation_targets = class_labels[validation_indices]\n",
    "    unique_classes, class_counts = np.unique(validation_targets, return_counts=True)\n",
    "    min_class_count = min(class_counts)\n",
    "\n",
    "    balanced_validation_indices = []\n",
    "    for cls in unique_classes:\n",
    "        cls_indices = validation_indices[validation_targets == cls]\n",
    "        balanced_validation_indices.extend(np.random.choice(cls_indices, min_class_count, replace=False))\n",
    "\n",
    "    # Create subsets using the indices\n",
    "    train_subset = torch.utils.data.Subset(train_dataset, train_indices)\n",
    "    validation_subset = torch.utils.data.Subset(train_dataset, balanced_validation_indices)\n",
    "    print(type(train_subset),type(validation_subset))\n",
    "    #validation split ensuring equal represntation of classes\n",
    "\n",
    "    class_labels = np.array(train_dataset.targets)\n",
    "\n",
    "    validation_size = 0.2\n",
    "\n",
    "    stratified_splitter = StratifiedShuffleSplit(n_splits=1, test_size=validation_size, random_state=42)\n",
    "\n",
    "\n",
    "    train_indices, validation_indices = next(stratified_splitter.split(train_dataset, class_labels))\n",
    "\n",
    "    # Create a balanced validation subset\n",
    "    validation_targets = class_labels[validation_indices]\n",
    "    unique_classes, class_counts = np.unique(validation_targets, return_counts=True)\n",
    "    min_class_count = min(class_counts)\n",
    "\n",
    "    balanced_validation_indices = []\n",
    "    for cls in unique_classes:\n",
    "        cls_indices = validation_indices[validation_targets == cls]\n",
    "        balanced_validation_indices.extend(np.random.choice(cls_indices, min_class_count, replace=False))\n",
    "\n",
    "    # Create subsets using the indices\n",
    "    train_subset = torch.utils.data.Subset(train_dataset, train_indices)\n",
    "    validation_subset = torch.utils.data.Subset(train_dataset, balanced_validation_indices)\n",
    "    print(type(train_subset),type(validation_subset))\n",
    "\n",
    "# Now train_subset and validation_subset contain data with balanced class representation\n",
    "  \n",
    "    trainloader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "    validationloader = torch.utils.data.DataLoader(validation_subset, batch_size=batch_size, shuffle=True)\n",
    "    testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    print(type(trainloader))\n",
    "    # Check images\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = next(dataiter)\n",
    "\n",
    "    print(\"the images batch\",images.shape)\n",
    "\n",
    "    print(\"a single item\",images[3].shape)\n",
    "    print(\"label of item\",labels[3].item())\n",
    "    #visualising\n",
    "    img = images[3]\n",
    "    print(type(img))\n",
    "    npimg = img.numpy()\n",
    "    print(npimg.shape)\n",
    "    npimg = np.transpose(npimg, (1, 2, 0))\n",
    "    print(npimg.shape)\n",
    "    plt.figure(figsize = (4,4))\n",
    "    plt.imshow(npimg)\n",
    "    plt.title(classes[labels[3]])\n",
    "    plt.show()\n",
    "    imshow(torchvision.utils.make_grid(images))\n",
    "    print(' '.join(classes[labels[j]] for j in range(batch_size)))\n",
    "\n",
    "    return trainloader,validationloader,testloader\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import numpy as np\n",
    "\n",
    "def prepare(batch_size=64, use_data_augmentation=False):\n",
    "    # Common normalization and resize operations\n",
    "    common_transforms = [\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ]\n",
    "\n",
    "    # Define transformations for the training data with optional augmentation\n",
    "    if use_data_augmentation:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),  # Example augmentation\n",
    "            transforms.RandomRotation(10),  # Example augmentation\n",
    "            *common_transforms,\n",
    "        ])\n",
    "    else:\n",
    "        train_transform = transforms.Compose(common_transforms)\n",
    "\n",
    "    # Transformations for validation and test data (no augmentation)\n",
    "    test_transform = transforms.Compose(common_transforms)\n",
    "\n",
    "    train_data_path = '/home/bincy/A2/CS-6910-A2/inaturalist_12K/train'\n",
    "    test_data_path = '/home/bincy/A2/CS-6910-A2/inaturalist_12K/val'\n",
    "\n",
    "    # Load the training dataset with the train_transform\n",
    "    full_train_dataset = datasets.ImageFolder(train_data_path, transform=train_transform)\n",
    "\n",
    "    # Split the full training dataset into training and validation subsets\n",
    "    validation_size = 0.2\n",
    "    stratified_splitter = StratifiedShuffleSplit(n_splits=1, test_size=validation_size, random_state=42)\n",
    "    train_indices, validation_indices = next(stratified_splitter.split(np.array(full_train_dataset.targets), np.array(full_train_dataset.targets)))\n",
    "\n",
    "    # Create subsets for training and validation\n",
    "    train_subset = Subset(full_train_dataset, train_indices)\n",
    "    validation_dataset = datasets.ImageFolder(train_data_path, transform=test_transform)  # Reload with test_transform\n",
    "    validation_subset = Subset(validation_dataset, validation_indices)\n",
    "\n",
    "    # Load the test dataset with the test_transform\n",
    "    test_dataset = datasets.ImageFolder(test_data_path, transform=test_transform)\n",
    "\n",
    "    # Create DataLoaders for training, validation, and test datasets\n",
    "    trainloader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "    validationloader = DataLoader(validation_subset, batch_size=batch_size, shuffle=False)\n",
    "    testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return trainloader, validationloader, testloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img,figsize=(8,8)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv_layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): Sequential(\n",
      "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (dense_layers): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=2048, out_features=100, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.3, inplace=False)\n",
      "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10, in_channels=3, num_filters=[32, 32, 32, 32, 32],kernel_size=3, pool_size=2,drop_conv=0.2, drop_dense=0.3,dense_neurons=100,activation=\"ReLU\",use_batch_norm=True, use_data_augmentation=True):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        activations = {\n",
    "        \"ReLU\": nn.ReLU(),\n",
    "        \"Tanh\": nn.Tanh(),\n",
    "        \"GELU\": nn.GELU(),\n",
    "        \"SiLU\": nn.SiLU(), \n",
    "        \"Mish\": nn.Mish()}\n",
    "        for out_channels in num_filters:\n",
    "            kernel_size=kernel_size\n",
    "            padding=kernel_size//2\n",
    "\n",
    "            \n",
    "            \n",
    "            activation_function=activations.get(activation, nn.ReLU())\n",
    "\n",
    "        # Get the\n",
    "            self.conv_layers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding),\n",
    "                    #nn.ReLU(),\n",
    "                    activation_function,\n",
    "                    nn.MaxPool2d(pool_size),\n",
    "                    nn.Dropout(drop_conv)  # Adding dropout with probability 0.2\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            if use_batch_norm:\n",
    "                self.conv_layers.append(nn.BatchNorm2d(out_channels))  # Batch normalization layer\n",
    "            in_channels = out_channels\n",
    "        \n",
    "        # Define dense layers\n",
    "            \n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(num_filters[-1] * (256 // (pool_size**len(num_filters))) * (256 // (pool_size**len(num_filters))), dense_neurons),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_dense),  # Adding dropout with probability 0.2\n",
    "            nn.Linear(dense_neurons, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass input through convolutional layers\n",
    "        for layer in self.conv_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Pass output through dense layers\n",
    "        x = self.dense_layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model = CNN()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(dataloader,model):\n",
    "    total, correct = 0, 0\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    for data in dataloader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        loss = loss_fn(outputs, labels)\n",
    "                \n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (pred == labels).sum().item()\n",
    "        \n",
    "    return 100 * correct / total,loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(config):\n",
    "#def fit():\n",
    "    \n",
    "    wandb.login() \n",
    "    #wandb.init(project=\"CS6910 A2\",name=\"part a\")\n",
    "    \n",
    "    loss_epoch_arr = []\n",
    "    train_accuracy_arr=[]\n",
    "    validation_accuracy_arr=[]\n",
    "    loss_epoch_val=[]\n",
    "    activation = config['activation']\n",
    "    n=config['filter']\n",
    "   \n",
    "    batch_size = config['batch_size']\n",
    "    epochs = config['epochs']\n",
    "    drop_conv=config['drop_conv']\n",
    "    drop_dense=config['drop_dense']\n",
    "    kernel_size=config['kernel_size']\n",
    "    filter_mult=config['filter_mult']\n",
    "    dense_neurons=config['dense']\n",
    "    use_batch_norm=config['batch_normalization']\n",
    "    use_data_augmentation=config['data_augmentation']\n",
    "    trainloader,validationloader,testloader=prepare(batch_size,use_data_augmentation)\n",
    "   \n",
    "    device = torch.device(\"cuda:0\")\n",
    "    if filter_mult == 1:\n",
    "        num_filters = [n, n, n, n, n]\n",
    "    if filter_mult==2:\n",
    "        num_filters = [n* (2 ** i) for i in range(5)]\n",
    "    if filter_mult==0.5:\n",
    "        num_filters = [n//(2 ** i) for i in range(5)]\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    net = CNN(num_filters=num_filters,drop_conv=drop_conv,drop_dense=drop_dense,use_batch_norm=use_batch_norm,use_data_augmentation=use_data_augmentation,dense_neurons=dense_neurons,kernel_size=kernel_size,activation=activation).to(device)\n",
    "   \n",
    "    \n",
    "    print(net)\n",
    "    '''net = CNN(drop=drop,filter_mult=filter_mult).to(device)\n",
    "    print(net)'''\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    opt = optim.Adam(net.parameters())\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    n_iters = np.ceil(10000/batch_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            train_loss = loss_fn(outputs, labels)\n",
    "            train_loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            del inputs, labels, outputs\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            if i % 1000 == 0:\n",
    "                print('Iteration: %d/%d, Loss: %0.2f' % (i, n_iters, train_loss.item()))\n",
    "            \n",
    "        loss_epoch_arr.append(train_loss.item())\n",
    "        train_accuracy,t_loss=evaluation(trainloader,net)\n",
    "        model.eval()\n",
    "        validation_accuracy,validation_loss=evaluation(validationloader,net)\n",
    "        train_accuracy_arr.append(train_accuracy)\n",
    "        validation_accuracy_arr.append(validation_accuracy)\n",
    "        loss_epoch_val.append(validation_loss)\n",
    "            \n",
    "        print('Epoch: %d/%d, validayion acc: %0.2f,Train acc: %0.2f ,val loss: %0.2f, train loss: %0.2f'%(\n",
    "            epoch, epochs, \n",
    "            validation_accuracy,train_accuracy,validation_loss,train_loss.item()))\n",
    "        \n",
    "        wandb.log({\"accuracy_train\": train_accuracy, \"accuracy_validation\": validation_accuracy, \"loss_train\": train_loss.item(), \"loss_validation\": validation_loss, 'epochs': epoch})\n",
    "    \n",
    "        model.train()\n",
    "        \n",
    "        \n",
    "    plt.plot(loss_epoch_arr)\n",
    "    plt.show()\n",
    "    plt.plot(range(1, epochs + 1), train_accuracy_arr, label='Training Accuracy')\n",
    "    plt.plot(range(1, epochs + 1), validation_accuracy_arr, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy per Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "   with wandb.init() as run:\n",
    "        run_name = f'epoch_{wandb.config.epochs}_acti_{wandb.config.activation}__batchsize_{wandb.config.batch_size}__kernel_size_{wandb.config.kernel_size}_denseneurons_{wandb.config.dense}_filter_mult_{wandb.config.filter_mult}__drop_conv_{wandb.config.drop_conv}__drop_dense_{wandb.config.drop_dense}_filter_{wandb.config.filter}_aug_{wandb.config.data_augmentation}_batch_norm_{wandb.config.batch_normalization}'\n",
    "        wandb.run.name = run_name\n",
    "        print(run_name)\n",
    "        fit(wandb.config)\n",
    "        wandb.run.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 5hw6dye5\n",
      "Sweep URL: https://wandb.ai/bincyantonym/CS6910%20A2/sweeps/5hw6dye5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dndpq69j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: GELU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: Yes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: Yes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense: 1000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_conv: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrop_dense: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_mult: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 3\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbincyantonym\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/bincy/A2/CS-6910-A2/wandb/run-20240403_222244-dndpq69j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bincyantonym/CS6910%20A2/runs/dndpq69j' target=\"_blank\">stilted-sweep-1</a></strong> to <a href='https://wandb.ai/bincyantonym/CS6910%20A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bincyantonym/CS6910%20A2/sweeps/5hw6dye5' target=\"_blank\">https://wandb.ai/bincyantonym/CS6910%20A2/sweeps/5hw6dye5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bincyantonym/CS6910%20A2' target=\"_blank\">https://wandb.ai/bincyantonym/CS6910%20A2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bincyantonym/CS6910%20A2/sweeps/5hw6dye5' target=\"_blank\">https://wandb.ai/bincyantonym/CS6910%20A2/sweeps/5hw6dye5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bincyantonym/CS6910%20A2/runs/dndpq69j' target=\"_blank\">https://wandb.ai/bincyantonym/CS6910%20A2/runs/dndpq69j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_5_acti_GELU__batchsize_16__kernel_size_3_denseneurons_1000_filter_mult_1__drop_conv_0__drop_dense_0_filter_64_aug_Yes_batch_norm_Yes\n",
      "CNN(\n",
      "  (conv_layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): Dropout(p=0, inplace=False)\n",
      "    )\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): Dropout(p=0, inplace=False)\n",
      "    )\n",
      "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): Dropout(p=0, inplace=False)\n",
      "    )\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): Dropout(p=0, inplace=False)\n",
      "    )\n",
      "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): Dropout(p=0, inplace=False)\n",
      "    )\n",
      "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (dense_layers): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0, inplace=False)\n",
      "    (4): Linear(in_features=1000, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Iteration: 0/625, Loss: 2.28\n"
     ]
    }
   ],
   "source": [
    "sweep_config = {\n",
    "  \"name\": \"The initial random sweep-100 runs\",\n",
    "  \"metric\": {\n",
    "      \"name\": \"accuracy_validation\",\n",
    "      \"goal\": \"maximize\"\n",
    "  },\n",
    "  \"method\": \"random\",\n",
    "  \"parameters\": {\n",
    "        \"epochs\": {\n",
    "            \"values\": [3,5,8,10,15]\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            \"values\": [4,16,32]\n",
    "        },\n",
    "        \"filter\":{\n",
    "            \"values\":[32,64]\n",
    "        },\n",
    "        \"kernel_size\":{\n",
    "            \"values\":[3,5,7,11]\n",
    "        },\n",
    "        \"drop_conv\": {\n",
    "            \"values\": [0, 0.1,0.2]\n",
    "        },\n",
    "        \"drop_dense\": {\n",
    "            \"values\": [0, 0.2,0.3]\n",
    "        },\n",
    "        \"filter_mult\": {\n",
    "            \"values\": [1,0.5,2]\n",
    "        },\n",
    "        \"activation\": {\n",
    "            \"values\": [\"Tanh\",\"GELU\",\"SiLU\",\"Mish\"]  # Specify activation functions as strings\n",
    "        },\n",
    "        \"dense\": {\n",
    "            \"values\": [2000,1000]  # Specify activation functions as strings\n",
    "        },\n",
    "        \"data_augmentation\": {\"values\": [\"Yes\"]},\n",
    "        \"batch_normalization\": {\"values\": [\"Yes\"]},\n",
    "    }\n",
    "}\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"CS6910 A2\")\n",
    "wandb.agent(sweep_id, function = train,count=100)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "A1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
